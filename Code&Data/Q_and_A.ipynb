{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\devch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\devch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\devch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Download nltk resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    word_vectors = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read from Text file\n",
    "def read_textfile(file_path):\n",
    "    with open(file_path,'r', encoding = 'utf-8') as file:\n",
    "        text = file.read()\n",
    "        return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Glove embeddings\n",
    "glove_file_path = 'glove.42B.300d.txt'  # Path to GloVe embeddings file\n",
    "text_file_path = 'Data/alice_wonderland_chapter1.txt'\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)\n",
    "print(\"GloVe embeddings loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns processed text and original sentences in a list (2 outputs)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        preprocessed_sentences.append(' '.join(filtered_tokens))\n",
    "    return preprocessed_sentences, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_sentences_origs(text_sentences,processed_text,processed_query,embeddings, top_n):\n",
    "    # Vectorizer for document\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(processed_text)\n",
    "    doc_vocabulary = tfidf_vectorizer.vocabulary_\n",
    "\n",
    "    # Calculate GloVe Sentence Vectors for the document\n",
    "    glove_sentence_vectors = []\n",
    "    for sentence in processed_text:\n",
    "        # Tokenize and average GloVe embeddings for words in the sentence\n",
    "        word_embeddings = [embeddings[word] for word in sentence.split() if word in embeddings]\n",
    "        if word_embeddings:\n",
    "            sentence_vector = np.mean(word_embeddings, axis=0)\n",
    "            glove_sentence_vectors.append(sentence_vector)\n",
    "        else:\n",
    "            # Handle the case where no words in the sentence have GloVe embeddings\n",
    "            # You may choose to assign a default vector or skip the sentence\n",
    "            pass\n",
    "        \n",
    "    #Vectorizer for query based on document vocabulary\n",
    "    query_tfidf_vectorizer = TfidfVectorizer(vocabulary=doc_vocabulary)\n",
    "    query_tfidf_vector = query_tfidf_vectorizer.fit_transform(processed_query)\n",
    "\n",
    "    # Join the list of processed query words into a single string\n",
    "    processed_query_str = ' '.join(processed_query)\n",
    "\n",
    "    # Calculate GloVe Sentence Vector for the query sentence\n",
    "    query_glove_vector = np.mean([embeddings[word] for word in processed_query_str.split() if word in embeddings], axis=0)\n",
    "\n",
    "    # Compute cosine similarity between the query sentence and each sentence in the document\n",
    "    cosine_similarities = cosine_similarity(query_tfidf_vector, tfidf_matrix)\n",
    "    glove_cosine_similarities = cosine_similarity([query_glove_vector], glove_sentence_vectors)\n",
    "\n",
    "    # Flatten cosine_similarities to match the shape of glove_cosine_similarities[0]\n",
    "    cosine_similarities = cosine_similarities.flatten()\n",
    "\n",
    "    # Combine TF-IDF and GloVe Similarity\n",
    "    final_cosine_similarities = 0.5 * cosine_similarities + 0.5 * glove_cosine_similarities[0]\n",
    "\n",
    "    # Get indices of top 3 most similar sentences\n",
    "    top_indices = final_cosine_similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Get top 3 most similar sentences\n",
    "    top_sentences = [text_sentences[i] for i in top_indices]\n",
    "    return top_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_sentences_origs_alice(text_sentences,processed_text,processed_query,embeddings, top_n):\n",
    "    # Vectorizer for document\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(processed_text)\n",
    "    doc_vocabulary = tfidf_vectorizer.vocabulary_\n",
    "\n",
    "    # Calculate GloVe Sentence Vectors for the document\n",
    "    glove_sentence_vectors = []\n",
    "    for sentence in processed_text:\n",
    "        # Tokenize and average GloVe embeddings for words in the sentence\n",
    "        word_embeddings = [embeddings[word] for word in sentence.split() if word in embeddings]\n",
    "        if word_embeddings:\n",
    "            sentence_vector = np.mean(word_embeddings, axis=0)\n",
    "            glove_sentence_vectors.append(sentence_vector)\n",
    "        else:\n",
    "            # Handle the case where no words in the sentence have GloVe embeddings\n",
    "            # You may choose to assign a default vector or skip the sentence\n",
    "            pass\n",
    "\n",
    "    #Vectorizer for query based on document vocabulary\n",
    "    query_tfidf_vectorizer = TfidfVectorizer(vocabulary=doc_vocabulary)\n",
    "\n",
    "    query_tfidf_vector = query_tfidf_vectorizer.fit_transform(processed_query)\n",
    "\n",
    "    # Join the list of processed query words into a single string\n",
    "    processed_query_str = ' '.join(processed_query)\n",
    "\n",
    "    # Calculate GloVe Sentence Vector for the query sentence\n",
    "    query_glove_vector = np.mean([embeddings[word] for word in processed_query_str.split() if word in embeddings], axis=0)\n",
    "\n",
    "    # Compute cosine similarity between the query sentence and each sentence in the document\n",
    "    cosine_similarities = cosine_similarity(query_tfidf_vector, tfidf_matrix)\n",
    "    glove_cosine_similarities = cosine_similarity([query_glove_vector], glove_sentence_vectors)\n",
    "\n",
    "    # Flatten cosine_similarities to match the shape of glove_cosine_similarities[0]\n",
    "    cosine_similarities = cosine_similarities.flatten()\n",
    "\n",
    "    # Remove the last element from cosine_similarities to align shapes\n",
    "    cosine_similarities = cosine_similarities[:-1]\n",
    "\n",
    "    # Combine TF-IDF and GloVe Similarity\n",
    "    final_cosine_similarities = 0.5 * cosine_similarities + 0.5 * glove_cosine_similarities[0]\n",
    "\n",
    "    # Get indices of top 3 most similar sentences\n",
    "    top_indices = final_cosine_similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Get top 3 most similar sentences\n",
    "    top_sentences = [text_sentences[i] for i in top_indices]\n",
    "    return top_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alice in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_alice(file_path, query):\n",
    "    text = read_textfile(file_path)\n",
    "    processed_text, orig_sentences = preprocess_text(text)\n",
    "    processed_query,_ = preprocess_text(query)\n",
    "    print(\"Query: \", query)\n",
    "    top_sentences_alice = top_n_sentences_origs_alice(orig_sentences,processed_text, processed_query, glove_embeddings,3)\n",
    "    print(\"top 5 sentences are: \\n\")\n",
    "    for sentence in top_sentences_alice:\n",
    "        print(sentence)\n",
    "    print(\"------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try using function on Alice in Wonderland chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What was the three-legged table made of?\n",
      "top 5 sentences are: \n",
      "\n",
      "Suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and Alice’s first thought was that it might belong to one of the doors of the hall; but, alas!\n",
      "when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.\n",
      "Why, there’s hardly enough of me left to make one respectable person!”\n",
      "\n",
      "Soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words “EAT ME” were beautifully marked in currants.\n",
      "------------------\n",
      "\n",
      "Query:  What strange thing did Alice notice about the key she found?\n",
      "top 5 sentences are: \n",
      "\n",
      "when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.\n",
      "The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.\n",
      "There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (“which certainly was not here before,” said Alice,) and round the neck of the bottle was a paper label, with the words “DRINK ME,” beautifully printed on it in large letters.\n",
      "------------------\n",
      "\n",
      "Query:  What did Alice think when tumbling down stairs?\n",
      "top 5 sentences are: \n",
      "\n",
      "“Well!” thought Alice to herself, “after such a fall as this, I shall think nothing of tumbling down stairs!\n",
      "I think I could, if I only knew how to begin.” For, you see, so many out-of-the-way things had happened lately, that Alice had begun to think that very few things indeed were really impossible.\n",
      "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, “Oh dear!\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Data/alice_wonderland_chapter1.txt\"\n",
    "\n",
    "queries = [\"What was the three-legged table made of?\",\n",
    "           \"What strange thing did Alice notice about the key she found?\",\n",
    "           \"What did Alice think when tumbling down stairs?\"]\n",
    "\n",
    "for query in queries:\n",
    "    ask_question_alice(file_path, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psychology Textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_psych(file_path, query):\n",
    "    text = read_textfile(file_path)\n",
    "    processed_text, orig_sentences = preprocess_text(text)\n",
    "    processed_query,_ = preprocess_text(query)\n",
    "    print(\"Query: \", query)\n",
    "    top_sentences_alice = top_n_sentences_wo_minus1_origs(orig_sentences,processed_text, processed_query, glove_embeddings,3)\n",
    "    print(\"top n sentences are: \\n\")\n",
    "    for sentence in top_sentences_alice:\n",
    "        print(sentence,\"\\n\")\n",
    "    print(\"----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  how are ideas traditionally perceived in contrast to the physical world?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n sentences are: \n",
      "\n",
      "So long as one does not carefully analyse the value of ideas, one remains under the impression that ideas form a world apart, which is sharply distinguished from the physical world, and behaves towards it as an antithesis. \n",
      "\n",
      "We can now consider the world [87]of ideas as a physical world; but it is one of a peculiar nature, which is not, like the other, accessible to all, and is subject to its own laws, which are laws of association. \n",
      "\n",
      "By these very different characteristics, it separates itself so sharply from the outer world that all endeavour to bring the two together seems shocking; and it is very easy to understand that many minds should wish to remain faithful to the conception that ideas form a mental or moral world. \n",
      "\n",
      "----------\n",
      "\n",
      "Query:  According to Descartes, what is the nature of the mind or soul?\n",
      "top n sentences are: \n",
      "\n",
      "Descartes, in his Discours de la Méthode (4th part), remarking that he may pretend \"not to have a body, and that there is no world or place in which he exists, but that he cannot pretend that he does not think,\" concludes by saying that the mind is \"a substance, all whose essence or nature is merely to think, and which has no need of either place or any other material thing, in order to exist;\" in short, that \"the soul is absolutely distinct from the body. \n",
      "\n",
      "Many excellent authors have made the domain of the mind begin in the ideal. \n",
      "\n",
      "We can now consider the world [87]of ideas as a physical world; but it is one of a peculiar nature, which is not, like the other, accessible to all, and is subject to its own laws, which are laws of association. \n",
      "\n",
      "----------\n",
      "\n",
      "Query:  What distinction is made between reality and truth in the passage?\n",
      "top n sentences are: \n",
      "\n",
      "This distinction between reality and truth ought to be likewise applied to mental images. \n",
      "\n",
      "For those, we propose to make a distinction between two notions, Existence or Reality, on the one hand, and Truth, on the other. \n",
      "\n",
      "Reality is that which is perceived or[85] conceived; truth is that which accords with the whole of our knowledge. \n",
      "\n",
      "----------\n",
      "\n",
      "Query:  How does the passage explain the relationship between sensation and image?\n",
      "top n sentences are: \n",
      "\n",
      "Taine has well described the phases of the reduction of the image by sensation: it is at the moment when it receives the shock of an image which contradicts it, that the image appears as illusory. \n",
      "\n",
      "Once acquainted with all these possibilities of errors, how can we suppose a radical separation between the sensation and the image? \n",
      "\n",
      "Now, it is very necessary that the image appear real to be usefully the substitute of the sensation past or to come. \n",
      "\n",
      "----------\n",
      "\n",
      "Query:  What is emphasized regarding the continuity between perception and ideation?\n",
      "top n sentences are: \n",
      "\n",
      "Further, there are thousands of circumstances where the ideation is neither in conflict with the perception nor isolated from it, but in logical continuity with it. \n",
      "\n",
      "Their logical composition is, indeed, that of an external perception, and there is in ideation exactly the same duality as in sensation. \n",
      "\n",
      "For is not conception the contrary of perception? \n",
      "\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Data/psych_text.txt\"\n",
    "\n",
    "queries = [\"how are ideas traditionally perceived in contrast to the physical world?\",\n",
    "           \"According to Descartes, what is the nature of the mind or soul?\",\n",
    "           \"What distinction is made between reality and truth in the passage?\",\n",
    "           \"How does the passage explain the relationship between sensation and image?\",\n",
    "           \"What is emphasized regarding the continuity between perception and ideation?\"\n",
    "           ]\n",
    "\n",
    "for query in queries:\n",
    "    ask_question_psych(file_path, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
